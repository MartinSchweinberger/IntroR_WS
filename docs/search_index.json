[["introduction-to-r.html", "Section 2 Introduction to R 2.1 Installing R and RStudio 2.2 Preparation 2.3 R and RStudio Basics 2.4 Getting started with R", " Section 2 Introduction to R UNFINISHED! WORK IN PROGRESS! I’M STILL WORKING ON THE CONTENT Here I want to show you how to get started with R. As such, this section is aimed at fresh users or beginners with the aim of showcasing how to set up a R session in RStudio, how to set up R projects, and how to do basic operations using R such as loading and manipulation tabular data and generating basic visualization using R. Here is an overview of cheat sheets for popular and frequently used packages provided by RStudio (cheat sheets are short overviews with explanations and examples of useful functions). If you already have experience with R, both @wickham2016r (see here) and @gillespie2016efficient (see here) are highly recommendable and excellent resources for improving your coding abilities and workflows in R. 2.1 Installing R and RStudio You have NOT yet installed R on your computer? You have a Windows computer? Then click here for downloading and installing R You have a Mac? Then click here for downloading and installing R You have NOT yet installed RStudio on your computer? Click here for downloading and installing RStudio. You can find a more elaborate explanation of how to download and install R and RStudio here that was created by the UQ library. 2.2 Preparation Before you actually open R or RStudio, there things to consider that make working in R much easier and give your workflow a better structure. Imagine it like this: when you want to write a book, you could simply take pen and paper and start writing or you could think about what you want to write about, what different chapters your book would consist of, which chapters to write first, what these chapters will deal with, etc. The same is true for R: you could simply open R and start writing code or you can prepare you session and structure what you will be doing. 2.2.1 Before you start working with R/RStudio (Folder Structure and R projects) Before actually starting with writing code, you should prepare the session by going through the following steps: 2.2.1.1 Create a folder for your project In that folder, create the following sub-folders (you can, of course, adapt this folder template to match your needs) data (you do not create this folder for the present workshop as you can simply use the data folder that you downloaded for this workshop instead) images tables docs The folder for your project could look like the the one shown below. Once you have created your project folder, you can go ahead with RStudio. 2.2.1.2 Open RStudio This is what RStudio looks like when you first open it: In RStudio, click on File You can use the drop-down menu to create a R project 2.2.1.3 R Projects In RStudio, click on New Project Next, confirm by clicking OK and select Existing Directory. Then, navigate to where you have just created the project folder for this workshop. Once you click on Open, you have created a new R project 2.2.1.4 R Notebooks In this project, click on File Click on New File and then on R Notebook as shown below. This R Notebook will be the file in which you do all your work. 2.2.1.5 Updating R In case you encounter issues when opening the R Notebook (e.g., if you receive an error message saying that you need to update packages which then do not install properly), you may have to update your R version. To update your current R version to the recent release please copy the code chunk shown below into the console pane (the bottom left pane) and click on Enter to run the code. The code will automatically update your version of R to the most recent release. During the update, you may be asked to specify some options - in that case, you can simply click on Accept and Next and accept the default settings. # install installr package install.packages(&quot;installr&quot;) # load installr package library(installr) # update r updateR() 2.2.1.6 Optimizing R project options When you work with projects, it is recommendable to control the so-called environment. This means that you make your R Project self-contained by storing all packages that are used in project in a library in the R Project (instead of in the general R library on your computer). Having a library in your R Project means that you can share your project folder wit other people and they will automatically have the same package versions that you have sued which makes your code more robust and reproducible. So, how to create such an environment? You simply click on Tools (at the very top right of RStudio), then click onProject Options then click on Environments and then check Use renv with this project. Now, when you install packages, they will be installed in the package library (rather than the general R library on your computer). 2.2.1.7 Getting started with R Notebooks You can now start writing in this R Notebook. For instance, you could start by changing the title of the R Notebook and describe what you are doing (what this Notebook contains). Below is a picture of what this document looked like when I started writing it. When you write in the R Notebook, you use what is called R Markdown which is explained below. 2.2.1.8 R Markdown The Notebook is an R Markdown document: a Rmd (R Markdown) file is more than a flat text document: it’s a program that you can run in R and which allows you to combine prose and code, so readers can see the technical aspects of your work while reading about their interpretive significance. You can get a nice and short overview of the formatting options in R Markdown (Rmd) files here. R Markdown allows you to make your research fully transparent and reproducible! If a couple of years down the line another researcher or a journal editor asked you how you have done your analysis, you can simply send them the Notebook or even the entire R-project folder. As such, Rmd files are a type of document that allows to include snippets of code (and any outputs such as tables or graphs) in plain text while encoding the structure of your document by using simple typographical symbols to encode formatting (rather than HTML tags or format types such as Main header or Header level 1 in Word). Markdown is really quite simple to learn and these resources may help: The Markdown Wikipedia page includes a very handy chart of the syntax. John Gruber developed Markdown and his introduction to the syntax is worth browsing. This interactive Markdown tutorial will teach you the syntax in a few minutes. 2.3 R and RStudio Basics RStudio is a so-called IDE - Integrated Development Environment. The interface provides easy access to R. The advantage of this application is that R programs and files as well as a project directory can be managed easily. The environment is capable of editing and running program code, viewing outputs and rendering graphics. Furthermore, it is possible to view variables and data objects of an R-script directly in the interface. 2.3.1 RStudio: Panes The GUI - Graphical User Interface - that RStudio provides divides the screen into four areas that are called panes: File editor Environment variables R console Management panes (File browser, plots, help display and R packages). The two most important are the R console (bottom left) and the File editor (or Script in the top left). The Environment variables and Management panes are on the right of the screen and they contain: Environment (top): Lists all currently defined objects and data sets History (top): Lists all commands recently used or associated with a project Plots (bottom): Graphical output goes here Help (bottom): Find help for R packages and functions. Don’t forget you can type ? before a function name in the console to get info in the Help section. Files (bottom): Shows the files available to you in your working directory These RStudio panes are shown below. 2.3.1.1 R Console (bottom left pane) The console pane allows you to quickly and immediately execute R code. You can experiment with functions here, or quickly print data for viewing. Type next to the &gt; and press Enter to execute. EXERCISE TIME! ` You can use R like a calculator. Try typing 2+8 into the R console. Answer 2+8 ## [1] 10 ` Here, the plus sign is the operator. Operators are symbols that represent some sort of action. However, R is, of course, much more than a simple calculator. To use R more fully, we need to understand objects, functions, and indexing - which we will learn about as we go. For now, think of objects as nouns and functions as verbs. 2.3.1.2 Running commands from a script To run code from a script, insert your cursor on a line with a command, and press CTRL/CMD+Enter. Or highlight some code to only run certain sections of the command, then press CTRL/CMD+Enter to run. Alternatively, use the Run button at the top of the pane to execute the current line or selection (see below). 2.3.1.3 Script Editor (top left pane) In contrast to the R console, which quickly runs code, the Script Editor (in the top left) does not automatically execute code. The Script Editor allows you to save the code essential to your analysis. You can re-use that code in the moment, refer back to it later, or publish it for replication. Now, that we have explored RStudio, we are ready to get started with R! 2.4 Getting started with R This section introduces some basic concepts and procedures that help optimize your workflow in R. 2.4.1 Setting up an R session At the beginning of a session, it is common practice to define some basic parameters. This is not required or even necessary, but it may just help further down the line. This session preparation may include specifying options. In the present case, we want R to show numbers as numbers up to 100 decimal points (and not show them in mathematical notation (in mathematical notation, 0.007 would be represented as 0.7e-3)) want R to show maximally 100 results (otherwise, it can happen that R prints out pages-after-pages of some numbers). Again, the session preparation is not required or necessary but it can help avoid errors. # set options options(stringsAsFactors = F) options(scipen = 100) options(max.print=100) In script editor pane of RStudio, this would look like this: 2.4.2 Packages When using R, most of the functions are not loaded or even installing automatically. Instead, most functions are in contained in what are called packages. R comes with about 30 packages (“base R”). There are over 10,000 user-contributed packages; you can discover these packages online. A prevalent collection of packages is the Tidyverse, which includes ggplot2, a package for making graphics. Before being able to use a package, we need to install the package (using the install.packages function) and load the package (using the library function). However, a package only needs to be installed once(!) and can then simply be loaded. When you install a package, this will likely install several other packages it depends on. You should have already installed tidyverse before the workshop. You must load the package in any new R session where you want to use that package. Below I show what you need to type when you want to install the tidyverse, the tidytext, the quanteda, the readxl, and the tm packages (which are the packages that we will need in this workshop). install.packages(&quot;tidyverse&quot;) install.packages(&quot;tidytext&quot;) install.packages(&quot;quanteda&quot;) install.packages(&quot;readxl&quot;) install.packages(&quot;tm&quot;) install.packages(&quot;tokenizers&quot;) install.packages(&quot;here&quot;) install.packages(&quot;flextable&quot;) # install klippy for copy-to-clipboard button in code chunks install.packages(&quot;remotes&quot;) remotes::install_github(&quot;rlesur/klippy&quot;) To load these packages, use the library function which takes the package name as its main argument. library(tidyverse) library(tidytext) library(quanteda) library(readxl) library(tm) library(tokenizers) library(here) library(flextable) # activate klippy for copy-to-clipboard button klippy::klippy() The session preparation section of your Rmd file will thus also state which packages a script relies on. In script editor pane of RStudio, the code blocks that install and activate packages would look like this: 2.4.3 Getting help When working with R, you will encounter issues and face challenges. A very good thing about R is that it provides various ways to get help or find information about the issues you face. 2.4.3.1 Finding help within R To get help regrading what functions a package contains, which arguments a function takes or to get information about how to use a function, you can use the help function or the apropos. function or you can simply type a ? before the package or two ?? if this does not give you any answers. help(tidyverse) apropos(&quot;tidyverse&quot;) ?require There are also other “official” help resources from R/RStudio. Read official package documentation, see vignettes, e.g., Tidyverse https://cran.r-project.org/package=tidyverse Use the RStudio Cheat Sheets at https://www.rstudio.com/resources/cheatsheets/ Use the RStudio Help viewer by typing ? before a function or package Check out the keyboard shortcuts Help under Tools in RStudio for some good tips 2.4.3.2 Finding help online One great thing about R is that you can very often find an answer to your question online. Google your error! See http://r4ds.had.co.nz/introduction.html#getting-help-and-learning-more for excellent suggestions on how to find help for a specific question online. "],["working-with-text.html", "Section 3 Working with Text 3.1 Functions and Objects 3.2 Inspecting data 3.3 Loading text data 3.4 Saving text data 3.5 Piping", " Section 3 Working with Text In this section, we will learn how to work with textual data in R and we use positive IMDB reviews as our example texts. Before we start, it is important to understand the general logic of R code which is why we start with a very brief explanation of functions and objects. 3.1 Functions and Objects In R, functions always have the following form: function(argument1, argument2, ..., argumentN). Typically a function does something to an object (e.g. a table), so that the first argument typically specifies the data to which the function is applied. Other arguments then allow to add some information. Just as a side note, functions are also objects that do not contain data but instructions. To assign content to an object, we use &lt;- or = so that the we provide a name for an object, and then assign some content to it. For example, MyObject &lt;- 1:20 means Create an object called MyObject. this object should contain the numbers 1 to 20. # generate an object MyObject &lt;- 1:20 # inspecting my object MyObject ## [1] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 3.2 Inspecting data There are many ways to inspect data. We will briefly go over the most common ways to inspect data. The head function takes the data-object as its first argument and automatically shows the first 6 elements of an object (or rows if the data-object has a table format). In contrast, the str function shows the structure of an object. # inspect first six elements of my object head(MyObject) ## [1] 1 2 3 4 5 6 # inspect structure of my object str(MyObject) ## int [1:20] 1 2 3 4 5 6 7 8 9 10 ... Next, we will learn how to load texts into R. 3.3 Loading text data There are many functions that we can use to load text data into R. For example, we can use the readLines function as shown below. text &lt;- readLines(here::here(&quot;data&quot;, &quot;reviews_pos/textpos1.txt&quot;)) # inspect first text element text ## [1] &quot;One of the other reviewers has mentioned that after watching just 1 Oz episode you&#39;ll be hooked. They are right, as this is exactly what happened with me.&lt;br /&gt;&lt;br /&gt;The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.&lt;br /&gt;&lt;br /&gt;It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.&lt;br /&gt;&lt;br /&gt;I would say the main appeal of the show is due to the fact that it goes where other shows wouldn&#39;t dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn&#39;t mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn&#39;t say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who&#39;ll be sold out for a nickel, inmates who&#39;ll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.&quot; To load many texts, we can use a loop to read all texts in a folder as shown below. In a first step, we define the paths of the texts and then, we use the map_chr function from the purrr package to loop over the paths and read them into R. In addition, we add names to the texts based on the paths from where the texts were loaded. # define paths reviews_pos &lt;- list.files(here::here(&quot;data/reviews_pos&quot;), full.names = T, pattern = &quot;.*txt&quot;) %&gt;% # load data purrr::map_chr(~ readr::read_file(.)) # add names names(reviews_pos) &lt;- list.files(here::here(&quot;data/reviews_pos&quot;), pattern = &quot;.*txt&quot;) %&gt;% stringr::str_remove_all(&quot;.txt&quot;) # inspect first text element reviews_pos[1] ## textpos1 ## &quot;One of the other reviewers has mentioned that after watching just 1 Oz episode you&#39;ll be hooked. They are right, as this is exactly what happened with me.&lt;br /&gt;&lt;br /&gt;The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.&lt;br /&gt;&lt;br /&gt;It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.&lt;br /&gt;&lt;br /&gt;I would say the main appeal of the show is due to the fact that it goes where other shows wouldn&#39;t dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn&#39;t mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn&#39;t say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who&#39;ll be sold out for a nickel, inmates who&#39;ll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\\r\\n&quot; 3.4 Saving text data To save a single text file, we can use writeLines function which only needs the text and the location where the text should be saved as its arguments. writeLines(reviews_pos[1], here::here(&quot;data&quot;, &quot;review_pos_text1.txt&quot;)) To save many text files on your computer, you need to first define the locations where you want to save the texts and then, in a second step, you save the files (as shown below). IMPORTANT: I have created a folder called output in my data folder in which the texts will be saved! # define where to save each file outs &lt;- file.path(paste0(here::here(), &quot;/&quot;, &quot;data/output&quot;, &quot;/&quot;, names(reviews_pos), &quot;.txt&quot;, sep = &quot;&quot;)) head(outs) ## [1] &quot;F:/data recovery/Uni/UQ/SLC/LADAL/workshops/IntroR_WS/data/output/textpos1.txt&quot; ## [2] &quot;F:/data recovery/Uni/UQ/SLC/LADAL/workshops/IntroR_WS/data/output/textpos10.txt&quot; ## [3] &quot;F:/data recovery/Uni/UQ/SLC/LADAL/workshops/IntroR_WS/data/output/textpos100.txt&quot; ## [4] &quot;F:/data recovery/Uni/UQ/SLC/LADAL/workshops/IntroR_WS/data/output/textpos1000.txt&quot; ## [5] &quot;F:/data recovery/Uni/UQ/SLC/LADAL/workshops/IntroR_WS/data/output/textpos101.txt&quot; ## [6] &quot;F:/data recovery/Uni/UQ/SLC/LADAL/workshops/IntroR_WS/data/output/textpos102.txt&quot; IMPORTANT: I have set the chunk attribute eval to F (FALSE) so that this chunk is not executed automatically. To run the code chunk, please just click the green “play button” in the top right corner of the code chunk. # save the files lapply(seq_along(reviews_pos), function(i) writeLines(reviews_pos[[i]], con = outs[i])) 3.5 Piping Piping is done using the %&gt;% sequence and it can be translated as and then. In the example below, we take the existing object (text) and then we convert it to upper case and then we store the result in a new object (text2). text %&gt;% toupper() -&gt; text2 # inspect data text2 ## [1] &quot;ONE OF THE OTHER REVIEWERS HAS MENTIONED THAT AFTER WATCHING JUST 1 OZ EPISODE YOU&#39;LL BE HOOKED. THEY ARE RIGHT, AS THIS IS EXACTLY WHAT HAPPENED WITH ME.&lt;BR /&gt;&lt;BR /&gt;THE FIRST THING THAT STRUCK ME ABOUT OZ WAS ITS BRUTALITY AND UNFLINCHING SCENES OF VIOLENCE, WHICH SET IN RIGHT FROM THE WORD GO. TRUST ME, THIS IS NOT A SHOW FOR THE FAINT HEARTED OR TIMID. THIS SHOW PULLS NO PUNCHES WITH REGARDS TO DRUGS, SEX OR VIOLENCE. ITS IS HARDCORE, IN THE CLASSIC USE OF THE WORD.&lt;BR /&gt;&lt;BR /&gt;IT IS CALLED OZ AS THAT IS THE NICKNAME GIVEN TO THE OSWALD MAXIMUM SECURITY STATE PENITENTARY. IT FOCUSES MAINLY ON EMERALD CITY, AN EXPERIMENTAL SECTION OF THE PRISON WHERE ALL THE CELLS HAVE GLASS FRONTS AND FACE INWARDS, SO PRIVACY IS NOT HIGH ON THE AGENDA. EM CITY IS HOME TO MANY..ARYANS, MUSLIMS, GANGSTAS, LATINOS, CHRISTIANS, ITALIANS, IRISH AND MORE....SO SCUFFLES, DEATH STARES, DODGY DEALINGS AND SHADY AGREEMENTS ARE NEVER FAR AWAY.&lt;BR /&gt;&lt;BR /&gt;I WOULD SAY THE MAIN APPEAL OF THE SHOW IS DUE TO THE FACT THAT IT GOES WHERE OTHER SHOWS WOULDN&#39;T DARE. FORGET PRETTY PICTURES PAINTED FOR MAINSTREAM AUDIENCES, FORGET CHARM, FORGET ROMANCE...OZ DOESN&#39;T MESS AROUND. THE FIRST EPISODE I EVER SAW STRUCK ME AS SO NASTY IT WAS SURREAL, I COULDN&#39;T SAY I WAS READY FOR IT, BUT AS I WATCHED MORE, I DEVELOPED A TASTE FOR OZ, AND GOT ACCUSTOMED TO THE HIGH LEVELS OF GRAPHIC VIOLENCE. NOT JUST VIOLENCE, BUT INJUSTICE (CROOKED GUARDS WHO&#39;LL BE SOLD OUT FOR A NICKEL, INMATES WHO&#39;LL KILL ON ORDER AND GET AWAY WITH IT, WELL MANNERED, MIDDLE CLASS INMATES BEING TURNED INTO PRISON BITCHES DUE TO THEIR LACK OF STREET SKILLS OR PRISON EXPERIENCE) WATCHING OZ, YOU MAY BECOME COMFORTABLE WITH WHAT IS UNCOMFORTABLE VIEWING....THATS IF YOU CAN GET IN TOUCH WITH YOUR DARKER SIDE.&quot; "],["basic-string-processing.html", "Section 4 Basic String Processing 4.1 Extracting frequency information from text 4.2 Regular Expressions 4.3 Practice: regular expressions", " Section 4 Basic String Processing Before turning to more advanced string processing (in the context of computation, texts are referred to as strings) using the stringr package, let us just focus on some basic functions that are extremely useful when working with texts. To practice working with texts, we will rename a shirt positive IMDB review and also generate a tokenized version of this review. Tokenizsation: Tokenization is the process of breaking down text into smaller units called tokens. These tokens can be symbols, words, phrases, sentences, or other meaningful elements (e.g. paragraphs). Tokenization is a fundamental step in natural language processing (NLP) and text analysis, as it allows for the text to be analysed and processed systematically.. review &lt;- reviews_pos[4] review_tok &lt;- quanteda::tokens(review) %&gt;% unlist() %&gt;% as.vector() # inspect review; str(review_tok) ## textpos1000 ## &quot;Gary Busey is superb in this musical biography. Great singing and excellent soundtrack. The Buddy Holly Story is a much better movie than La Bamba. From reading other comments, there may be some historical inaccuracies. Regardless, it is a fun toe-tapping film, and a good introduction to Buddy Holly&#39;s music.\\r\\n&quot; ## chr [1:58] &quot;Gary&quot; &quot;Busey&quot; &quot;is&quot; &quot;superb&quot; &quot;in&quot; &quot;this&quot; &quot;musical&quot; &quot;biography&quot; ... We can now start to check out functions that are useful and frequently applied to text data. We start by splitting text data. To split texts, we can use the str_split function. However, there are two issues when using this (very useful) function: the pattern that we want to split on disappears the output is a list (a special type of data format) To remedy these issues, we combine the str_split function with the unlist function add something right at the beginning of the pattern that we use to split the text. To add something to the beginning of the pattern that we want to split the text by, we use the str_replace_all function. The str_replace_all function takes three arguments, 1. the text, 2. the pattern that should be replaced, 3. the replacement. In the example below, we add ~~~ to the sequence movie and then split on the ~~~ rather than on the sequence “movie” (in other words, we replace movie with ~~~movie and then split on ~~~). # split text str_split( # attach ~~~ right before where we want to split (we want to split before the token &quot;movie&quot;) stringr::str_replace_all(reviews_pos, &quot;movie&quot;, &quot;~~~movie&quot;), # define that we want to split by ~~~ pattern = &quot;~~~&quot;) %&gt;% # unlist results unlist() -&gt; reviews_pos_split # inspect data nchar(reviews_pos_split); str(reviews_pos_split) ## [1] 1763 641 584 458 127 184 3847 152 685 30 105 92 43 27 11 ## [16] 716 465 417 262 107 59 747 370 1550 122 1693 714 45 726 80 ## [31] 224 906 250 521 1939 2708 1205 2572 819 717 28 109 211 31 554 ## [46] 289 914 440 65 561 62 196 33 55 40 200 121 616 82 135 ## [61] 293 47 280 21 232 89 99 353 2003 379 42 36 42 315 751 ## [76] 33 53 220 1147 1766 11 221 99 214 610 72 27 792 254 131 ## [91] 253 88 250 111 64 84 465 103 10 372 ## [ reached getOption(&quot;max.print&quot;) -- omitted 2747 entries ] ## chr [1:2847] &quot;One of the other reviewers has mentioned that after watching just 1 Oz episode you&#39;ll be hooked. They are right&quot;| __truncated__ ... A very useful function is, e.g. tolower which converts everything to lower case. tolower(review) ## textpos1000 ## &quot;gary busey is superb in this musical biography. great singing and excellent soundtrack. the buddy holly story is a much better movie than la bamba. from reading other comments, there may be some historical inaccuracies. regardless, it is a fun toe-tapping film, and a good introduction to buddy holly&#39;s music.\\r\\n&quot; Conversely, toupper converts everything to upper case. toupper(review) ## textpos1000 ## &quot;GARY BUSEY IS SUPERB IN THIS MUSICAL BIOGRAPHY. GREAT SINGING AND EXCELLENT SOUNDTRACK. THE BUDDY HOLLY STORY IS A MUCH BETTER MOVIE THAN LA BAMBA. FROM READING OTHER COMMENTS, THERE MAY BE SOME HISTORICAL INACCURACIES. REGARDLESS, IT IS A FUN TOE-TAPPING FILM, AND A GOOD INTRODUCTION TO BUDDY HOLLY&#39;S MUSIC.\\r\\n&quot; The stringr package (see here is part of the so-called tidyverse - a collection of packages that allows to write R code in a readable manner - and it is the most widely used package for string processing in . The advantage of using stringr is that it makes string processing very easy. All stringr functions share a common structure: str_function(string, pattern) The two arguments in the structure of stringr functions are: string which is the character string to be processed and a pattern which is either a simple sequence of characters, a regular expression, or a combination of both. Because the string comes first, the stringr functions are ideal for piping and thus use in tidyverse style R. All function names of stringr begin with str, then an underscore and then the name of the action to be performed. For example, to replace the first occurrence of a pattern in a string, we should use str_replace(). In the following, we will use stringr functions to perform various operations on the example text. As we have already loaded the tidyverse package, we can start right away with using stringr functions as shown below. Like nchar in base, str_count provides the number of characters of a text. str_count(reviews_pos[1:5]) ## [1] 1762 640 1041 310 3846 The function str_detect informs about whether a pattern is present in a text and outputs a logical vector with TRUE if the pattern occurs and FALSE if it does not. str_detect(review, &quot;and&quot;) ## [1] TRUE The function str_extract_all extracts all occurrences of a pattern, if that pattern is present in a text. str_extract_all(review, &quot;and&quot;) ## [[1]] ## [1] &quot;and&quot; &quot;and&quot; The function str_locate_all provides the start and end positions of the match of the pattern in a text and displays the result in matrix-form. str_locate_all(review, &quot;and&quot;) ## [[1]] ## start end ## [1,] 63 65 ## [2,] 263 265 The function str_match extracts the first occurrence of the pattern in a text. str_match(review, &quot;and&quot;) ## [,1] ## [1,] &quot;and&quot; The function str_match_all extracts the all occurrences of the pattern from a text. str_match_all(review, &quot;and&quot;) ## [[1]] ## [,1] ## [1,] &quot;and&quot; ## [2,] &quot;and&quot; The function str_remove removes the first occurrence of a pattern in a text. str_remove(review, &quot;and&quot;) ## [1] &quot;Gary Busey is superb in this musical biography. Great singing excellent soundtrack. The Buddy Holly Story is a much better movie than La Bamba. From reading other comments, there may be some historical inaccuracies. Regardless, it is a fun toe-tapping film, and a good introduction to Buddy Holly&#39;s music.\\r\\n&quot; The function str_remove_all removes all occurrences of a pattern from a text. str_remove_all(review, &quot;and&quot;) ## [1] &quot;Gary Busey is superb in this musical biography. Great singing excellent soundtrack. The Buddy Holly Story is a much better movie than La Bamba. From reading other comments, there may be some historical inaccuracies. Regardless, it is a fun toe-tapping film, a good introduction to Buddy Holly&#39;s music.\\r\\n&quot; The function str_replace_all replaces all occurrences of a pattern with something else in a text. str_replace_all(review, &quot;and&quot;, &quot;AND&quot;) ## [1] &quot;Gary Busey is superb in this musical biography. Great singing AND excellent soundtrack. The Buddy Holly Story is a much better movie than La Bamba. From reading other comments, there may be some historical inaccuracies. Regardless, it is a fun toe-tapping film, AND a good introduction to Buddy Holly&#39;s music.\\r\\n&quot; The function str_starts tests whether a given text begins with a certain pattern and outputs a logical vector. str_starts(review, &quot;and&quot;) ## [1] FALSE The function str_ends tests whether a text ends with a certain pattern and outputs a logical vector. str_ends(review, &quot;and&quot;) ## [1] FALSE Like strsplit, the function str_split splits a text when a given pattern occurs. If no pattern is provided, then the text is split into individual symbols. str_split(review, &quot;and&quot;) ## [[1]] ## [1] &quot;Gary Busey is superb in this musical biography. Great singing &quot; ## [2] &quot; excellent soundtrack. The Buddy Holly Story is a much better movie than La Bamba. From reading other comments, there may be some historical inaccuracies. Regardless, it is a fun toe-tapping film, &quot; ## [3] &quot; a good introduction to Buddy Holly&#39;s music.\\r\\n&quot; The function str_split_fixed splits a text when a given pattern occurs but only so often as is indicated by the argument n. So, even if the patter occur more often than n, str_split_fixed will only split the text n times. str_split_fixed(review, &quot;and&quot;, n = 3) ## [,1] ## [1,] &quot;Gary Busey is superb in this musical biography. Great singing &quot; ## [,2] ## [1,] &quot; excellent soundtrack. The Buddy Holly Story is a much better movie than La Bamba. From reading other comments, there may be some historical inaccuracies. Regardless, it is a fun toe-tapping film, &quot; ## [,3] ## [1,] &quot; a good introduction to Buddy Holly&#39;s music.\\r\\n&quot; The function str_subset extracts those subsets of a text that contain a certain pattern. str_subset(review_tok, &quot;and&quot;) ## [1] &quot;and&quot; &quot;and&quot; The function str_which provides a vector with the indices of the texts that contain a certain pattern. str_which(review_tok, &quot;and&quot;) ## [1] 12 50 The function str_view_all shows the locations of all instances of a pattern in a text or vector of texts. str_view_all(review, &quot;and&quot;) ## [1] │ Gary Busey is superb in this musical biography. Great singing &lt;and&gt; excellent soundtrack. The Buddy Holly Story is a much better movie than La Bamba. From reading other comments, there may be some historical inaccuracies. Regardless, it is a fun toe-tapping film, &lt;and&gt; a good introduction to Buddy Holly&#39;s music.{\\r} ## │ The function str_pad adds white spaces to a text or vector of texts so that they reach a given number of symbols. # create text with white spaces text &lt;- &quot; this is a text &quot; str_pad(text, width = 30) ## [1] &quot; this is a text &quot; The function str_trim removes white spaces from the beginning(s) and end(s) of a text or vector of texts. str_trim(text) ## [1] &quot;this is a text&quot; The function str_squish removes white spaces that occur within a text or vector of texts. str_squish(text) ## [1] &quot;this is a text&quot; The function str_wrap removes white spaces from the beginning(s) and end(s) of a text or vector of texts and also those white spaces that occur within a text or vector of texts. str_wrap(text) ## [1] &quot;this is a text&quot; The function str_order provides a vector that represents the order of a vector of texts according to the lengths of texts in that vector. str_order(reviews_pos_split) ## [1] 1522 2196 170 2011 1320 2161 231 1771 2525 1876 272 936 1413 287 1988 ## [16] 1276 40 1630 530 1727 168 127 2676 1826 2457 1420 438 2332 2696 528 ## [31] 910 2808 2279 828 2162 1580 2282 942 2081 2029 1811 2440 1036 2178 258 ## [46] 2024 622 1728 469 1196 1577 1606 772 1059 2227 1336 1963 313 1888 745 ## [61] 1202 1713 270 883 2126 2500 1111 2220 1965 1353 331 1558 1659 552 2339 ## [76] 1683 904 1144 323 2666 1803 698 70 1928 2016 2090 2747 1167 1007 1137 ## [91] 1175 25 2408 1663 2359 2576 1238 364 882 177 ## [ reached getOption(&quot;max.print&quot;) -- omitted 2747 entries ] The function str_sort orders of a vector of texts according to the lengths of texts in that vector. str_sort(reviews_pos_split) %&gt;% head() ## [1] &quot;...And there were quite a few of these. &lt;br /&gt;&lt;br /&gt;I do not like this cartoon as much as many others, partly because it was made in its period. I much prefer cartoons with Daffy and Bugs which are fifteen or so years before-hand. Many people will like this, particularly people who always find violence funny, cartoon or not.&lt;br /&gt;&lt;br /&gt;The basic plot is a pretty well known one for Looney Tunes: Elmer goes out hunting, Daffy leads him to Bugs and Daffy ends up being shot instead. Also inserted are quite clever and highly entertaining jokes (some do not enhance the episode), ugly shooting and animation which is slightly mediocre. The plot is mainly geared by jokes - each joke keeps the episode going. This way of plot-going is not all that unusual in Looney Tunes (of course if you are pretty much a Looney Tunes boffin - or an eager one - like me, then you&#39;ll know this already).&lt;br /&gt;&lt;br /&gt;For people who love everything about Looney Tunes and Daffy Duck and like the sound of what I have said about it, enjoy \\&quot;Rabbit Seasoning\\&quot;!&lt;br /&gt;&lt;br /&gt;7 and a half out of ten.\\r\\n&quot; ## [2] &quot;&#39;Had Ned Kelly been born later he probably would have won a Victoria Cross at Gallipolli&#39;. such was Ned&#39;s Bravery.&lt;br /&gt;&lt;br /&gt;In Australia and especially country Victoria the name Ned Kelly can be said and immediately recognised. In Greta he is still a Hero, the life Blood of the Town of Jerilderie depends on the tourism he created, but in Mansfield they still haven&#39;t forgotten that the three policeman that he &#39;murdered&#39; were from there.&lt;br /&gt;&lt;br /&gt;Many of the buildings he visited in his life are still standing. From the Old Melbourne Gaol where he was hanged, to the Post office he held up in Jerilderie. A cell he was once held in in Greta is on display in Benella and the site of Ann Jones&#39; Hotel, the station and even the logs where he was captured in Glenrowan can be visited.&lt;br /&gt;&lt;br /&gt;Evidence of all the events in the &quot; ## [3] &quot;&#39;War &quot; ## [4] &quot;&#39;What I Like About You&#39; is definitely a show that I couldn&#39;t wait to see each day. Amanda Bynes is such an excellent actress and I grew up watching her show: &#39;The Amanda Show.&#39; She&#39;s a very funny person and seems to be down to earth. \\&quot;Holly\\&quot; is such a like-able person and has an \\&quot;out-there\\&quot; personality. I enjoyed how she always seemed to turn things around and upside down, so she messed herself up at times. But that&#39;s what made the show so great.&lt;br /&gt;&lt;br /&gt;I especially loved the show when the character &#39;Vince&#39; came along. Nick Zano is very HOT and funny, as well as &#39;Gary&#39;, Wesley Jonathan. The whole cast was great, each character had their own personality and charm. Jennie Garth, Allison Munn, and Leslie Grossman were all very interesting. I especially loved &#39;Lauren&#39;; she&#39;s the best! She helped make the show extra funny and you never know what she&#39;s gonna do or say next! Overall the show is really nice but the reason I didn&#39;t give it a 10 was because there&#39;s no more new episodes and because the episodes could&#39;ve been longer and more deep.\\r\\n&quot; ## [5] &quot;\\&quot; Så som i himmelen \\&quot; .. as above so below.. that very special point where Divine and Human meet. I ADORE this film ! A gem. YES amazing grace !&lt;br /&gt;&lt;br /&gt;I was so deeply moved by its very HUMAN quality. I laughed and cried through a whole register , indeed several octaves of emotions.&lt;br /&gt;&lt;br /&gt;Mikael Nyqvist ís BRILLIANT as Daniel , a first rate passionate performance, charismatic and powerful. His inner light and exceptional talent shines through in every scene, every interaction ,in every meeting. I was totally mesmerised, enchanted and caught up the story, which is our collective story, the story of life itself.&lt;br /&gt;&lt;br /&gt;The film was also so inclusive of many archetypes, messiah, wounded child ,magical child, artist, teacher, priest, abuser, abused, victim, bully, divine fool - ALL the characters so real and true to life - all awakened great fondness and compassion in me. &lt;br /&gt;&lt;br /&gt;It is a real treat to see such a thought provoking yet thoroughly enjoyable, entertaining film. Oh ..mustn&#39;t forget the heavenly choir of angels and breathtakingly beautiful sound. &lt;br /&gt;&lt;br /&gt;THANK YOU ALL - This Swedish film will surely captivate people world-wide. BRILLIANT !\\r\\n&quot; ## [6] &quot;\\&quot;Ah Ritchie&#39;s made another gangster film with Statham\\&quot; thought the average fan, expecting another Snatch/Lock Stock; expecting perhaps a couple of temporal shifts, but none too hard for \\&quot;me and the lads\\&quot; to swallow after a few beers.&lt;br /&gt;&lt;br /&gt;Ah, pay attention, you do need to watch this film. No cups of tea, no extra diet cokes from the counter, no \\&quot;keep it running\\&quot; shouts as you nip to the fridge - watch the film! No laughs other than those you may make yourself from the considerable violence (and if that floats your boat, so be it) but sharp solid direction, excellent dialogue, and great performances.&lt;br /&gt;&lt;br /&gt;My favourite - Big Pussy from The Sopranos, always a reliable hood.\\r\\n&quot; The function str_c combines texts into one text str_c(review, reviews_pos[7]) ## [1] &quot;Gary Busey is superb in this musical biography. Great singing and excellent soundtrack. The Buddy Holly Story is a much better movie than La Bamba. From reading other comments, there may be some historical inaccuracies. Regardless, it is a fun toe-tapping film, and a good introduction to Buddy Holly&#39;s music.\\r\\nI think this is one hell of a movie...........We can see Steven fighting around with his martial art stuff again and like in all Segal movies there&#39;s a message in it, without the message it would be one of many action/fighting movies but the message is what makes segal movies great and special.\\r\\n&quot; The function str_conv converts a text into a certain type of encoding, e.g. into UTF-8 or Latin1. str_conv(review, encoding = &quot;UTF-8&quot;) ## [1] &quot;Gary Busey is superb in this musical biography. Great singing and excellent soundtrack. The Buddy Holly Story is a much better movie than La Bamba. From reading other comments, there may be some historical inaccuracies. Regardless, it is a fun toe-tapping film, and a good introduction to Buddy Holly&#39;s music.\\r\\n&quot; The function str_dup reduplicates a text or a vector of texts n times. str_dup(review, times=2) ## [1] &quot;Gary Busey is superb in this musical biography. Great singing and excellent soundtrack. The Buddy Holly Story is a much better movie than La Bamba. From reading other comments, there may be some historical inaccuracies. Regardless, it is a fun toe-tapping film, and a good introduction to Buddy Holly&#39;s music.\\r\\nGary Busey is superb in this musical biography. Great singing and excellent soundtrack. The Buddy Holly Story is a much better movie than La Bamba. From reading other comments, there may be some historical inaccuracies. Regardless, it is a fun toe-tapping film, and a good introduction to Buddy Holly&#39;s music.\\r\\n&quot; The function str_flatten combines a vector of texts into one text. The argument collapse defines the symbol that occurs between the combined texts. If the argument collapse is left out, the texts will be combined without any symbol between the combined texts. str_flatten(c(review, reviews_pos[7]), collapse = &quot; &quot;) ## [1] &quot;Gary Busey is superb in this musical biography. Great singing and excellent soundtrack. The Buddy Holly Story is a much better movie than La Bamba. From reading other comments, there may be some historical inaccuracies. Regardless, it is a fun toe-tapping film, and a good introduction to Buddy Holly&#39;s music.\\r\\n I think this is one hell of a movie...........We can see Steven fighting around with his martial art stuff again and like in all Segal movies there&#39;s a message in it, without the message it would be one of many action/fighting movies but the message is what makes segal movies great and special.\\r\\n&quot; The function str_length provides the length of texts in characters. str_length(review) ## [1] 311 The function str_replace_na replaces NA in texts. It is important to note that NA, if it occurs within a string, is considered to be the literal string NA. # create sentences with NA sentencesna &lt;- c(&quot;Some text&quot;, NA, &quot;Some more text&quot;, &quot;Some NA text&quot;) # apply str_replace_na function str_replace_na(sentencesna, replacement = &quot;Something new&quot;) ## [1] &quot;Some text&quot; &quot;Something new&quot; &quot;Some more text&quot; &quot;Some NA text&quot; The function str_trunc ends strings with … after a certain number of characters. str_trunc(review, width = 20) ## textpos1000 ## &quot;Gary Busey is sup...&quot; The function str_sub extracts a string from a text from a start location to an end position (expressed as character positions). str_sub(review, 5, 25) ## [1] &quot; Busey is superb in t&quot; The function word extracts words from a text (expressed as word positions). word(review, 2:7) ## [1] &quot;Busey&quot; &quot;is&quot; &quot;superb&quot; &quot;in&quot; &quot;this&quot; &quot;musical&quot; The function str_glue combines strings and allows to input variables. name &lt;- &quot;Fred&quot; age &lt;- 50 anniversary &lt;- as.Date(&quot;1991-10-12&quot;) str_glue( &quot;My name is {name}, &quot;, &quot;my age next year is {age + 1}, &quot;, &quot;and my anniversary is {format(anniversary, &#39;%A, %B %d, %Y&#39;)}.&quot; ) ## My name is Fred, my age next year is 51, and my anniversary is Saturday, October 12, 1991. 4.1 Extracting frequency information from text Frequency lists are very basic but also important when analysing text. Fortunately, it is very easy to extract frequency information and to create frequency lists with R. We can do this by first using the unnest_tokens function which splits texts into individual words, an then use the count function to get the raw frequencies of all word types in a text. reviews_pos %&gt;% # convert to data frame as.data.frame()%&gt;% # give name column with text dplyr::rename(text = 1) %&gt;% # tokenise tidytext::unnest_tokens(word, text) %&gt;% # count tokens dplyr::count(word, sort=T) %&gt;% # inspect 20 most frequent tokens head(20) ## word n ## 1 the 13395 ## 2 and 6869 ## 3 a 6487 ## 4 of 5998 ## 5 to 5153 ## 6 is 4351 ## 7 br 3968 ## 8 in 3827 ## 9 it 2982 ## 10 i 2935 ## 11 this 2845 ## 12 that 2552 ## 13 as 2025 ## 14 with 1817 ## 15 was 1709 ## 16 for 1699 ## 17 but 1571 ## 18 film 1558 ## 19 movie 1527 ## 20 on 1436 Extracting N-grams is also very easy as the unnest_tokens function can an argument called token in which we can specify that we want to extract n-grams, If we do this, then we need to specify the n as a separate argument. Below we specify that we want the frequencies of all 4-grams. reviews_pos %&gt;% # convert to data frame as.data.frame()%&gt;% # give name column with text dplyr::rename(text = 1) %&gt;% # clean data dplyr::mutate(text = str_remove_all(text, &quot;&lt;.*?&gt;&quot;)) %&gt;% # tokenise and extract trigrams tidytext:: unnest_tokens(word, text, token=&quot;ngrams&quot;, n=3) %&gt;% # count tokens dplyr::count(word, sort=T) %&gt;% # inspect ten most frequent tri-grams head(10) ## word n ## 1 one of the 219 ## 2 this is a 127 ## 3 some of the 96 ## 4 is one of 92 ## 5 of the film 92 ## 6 this movie is 89 ## 7 a lot of 85 ## 8 this film is 70 ## 9 of the best 68 ## 10 of the movie 68 4.2 Regular Expressions In this section, we focus on regular expressions (to learn more about regular expression, have a look at this very recommendable tutorial). Regular expressions are powerful tools used to search and manipulate text patterns. They provide a way to find specific sequences of characters within larger bodies of text. There are two basic types of regular expressions: regular expressions that stand for frequencies (quantifiers) regular expressions that stand for classes of symbols (types) The regular expressions below show the first type of regular expressions, i.e. quantifiers. The regular expressions below show the second type of regular expressions, i.e. types. Types can be expanded to include structural properties as shown below. 4.3 Practice: regular expressions We now want to show all words in the tokenized review that contain y. review_tok[str_detect(review_tok, &quot;[y]&quot;)] ## [1] &quot;Gary&quot; &quot;Busey&quot; &quot;biography&quot; &quot;Buddy&quot; &quot;Holly&quot; &quot;Story&quot; ## [7] &quot;may&quot; &quot;Buddy&quot; &quot;Holly&#39;s&quot; Show all words in the split tokenized review that begin with a lower case a. review_tok[str_detect(review_tok, &quot;^a&quot;)] ## [1] &quot;and&quot; &quot;a&quot; &quot;a&quot; &quot;and&quot; &quot;a&quot; Show all words in the split tokenized review that end in a lower case s. review_tok[str_detect(review_tok, &quot;s$&quot;)] ## [1] &quot;is&quot; &quot;this&quot; &quot;is&quot; &quot;comments&quot; &quot;inaccuracies&quot; ## [6] &quot;Regardless&quot; &quot;is&quot; &quot;Holly&#39;s&quot; Show all words in the split tokenized review in which there is an e, then any other character, and than another n. review_tok[str_detect(review_tok, &quot;o..y&quot;)] ## [1] &quot;Holly&quot; &quot;Holly&#39;s&quot; Show all words in the tokenized review text in which there is an e, then two other characters, and than another n. review_tok[str_detect(review_tok, &quot;o.{2,2}y&quot;)] ## [1] &quot;Holly&quot; &quot;Holly&#39;s&quot; Show all words that consist of exactly three alphabetical characters in the tokenized review . review_tok[str_detect(review_tok, &quot;^[:alpha:]{3,3}$&quot;)] ## [1] &quot;and&quot; &quot;The&quot; &quot;may&quot; &quot;fun&quot; &quot;and&quot; Show all words that consist of six or more alphabetical characters in the tokenized review. review_tok[str_detect(review_tok, &quot;^[:alpha:]{6,}$&quot;)] ## [1] &quot;superb&quot; &quot;musical&quot; &quot;biography&quot; &quot;singing&quot; &quot;excellent&quot; ## [6] &quot;soundtrack&quot; &quot;better&quot; &quot;reading&quot; &quot;comments&quot; &quot;historical&quot; ## [11] &quot;inaccuracies&quot; &quot;Regardless&quot; &quot;introduction&quot; Replace all lower case as with upper case Es in the review. str_replace_all(review, &quot;a&quot;, &quot;E&quot;) ## [1] &quot;GEry Busey is superb in this musicEl biogrEphy. GreEt singing End excellent soundtrEck. The Buddy Holly Story is E much better movie thEn LE BEmbE. From reEding other comments, there mEy be some historicEl inEccurEcies. RegErdless, it is E fun toe-tEpping film, End E good introduction to Buddy Holly&#39;s music.\\r\\n&quot; Remove all non-alphabetical characters in the tokenized review. str_remove_all(review_tok, &quot;\\\\W&quot;) ## [1] &quot;Gary&quot; &quot;Busey&quot; &quot;is&quot; &quot;superb&quot; &quot;in&quot; ## [6] &quot;this&quot; &quot;musical&quot; &quot;biography&quot; &quot;&quot; &quot;Great&quot; ## [11] &quot;singing&quot; &quot;and&quot; &quot;excellent&quot; &quot;soundtrack&quot; &quot;&quot; ## [16] &quot;The&quot; &quot;Buddy&quot; &quot;Holly&quot; &quot;Story&quot; &quot;is&quot; ## [21] &quot;a&quot; &quot;much&quot; &quot;better&quot; &quot;movie&quot; &quot;than&quot; ## [26] &quot;La&quot; &quot;Bamba&quot; &quot;&quot; &quot;From&quot; &quot;reading&quot; ## [31] &quot;other&quot; &quot;comments&quot; &quot;&quot; &quot;there&quot; &quot;may&quot; ## [36] &quot;be&quot; &quot;some&quot; &quot;historical&quot; &quot;inaccuracies&quot; &quot;&quot; ## [41] &quot;Regardless&quot; &quot;&quot; &quot;it&quot; &quot;is&quot; &quot;a&quot; ## [46] &quot;fun&quot; &quot;toetapping&quot; &quot;film&quot; &quot;&quot; &quot;and&quot; ## [51] &quot;a&quot; &quot;good&quot; &quot;introduction&quot; &quot;to&quot; &quot;Buddy&quot; ## [56] &quot;Hollys&quot; &quot;music&quot; &quot;&quot; Remove all white spaces in the review. str_remove_all(review, &quot; &quot;) ## [1] &quot;GaryBuseyissuperbinthismusicalbiography.Greatsingingandexcellentsoundtrack.TheBuddyHollyStoryisamuchbettermoviethanLaBamba.Fromreadingothercomments,theremaybesomehistoricalinaccuracies.Regardless,itisafuntoe-tappingfilm,andagoodintroductiontoBuddyHolly&#39;smusic.\\r\\n&quot; "],["advanced-string-processing.html", "Section 5 Advanced String Processing 5.1 Stemming 5.2 Part-of-speech tagging and dependency parsing 5.3 Example: Data processing chain 5.4 Concordancing and KWICs", " Section 5 Advanced String Processing Above, we have used functions and regular expressions to extract and find patters in textual data. Here, we will focus on common methods for cleaning text data that are applied before implementing certain methods. We start by installing and then loading some additional packages, e.g., the quanteda (see here for a cheat sheet for the quanteda package), the tm, and the udpipe package, which are extremely useful when dealing with more advanced text processing. install.packages(&quot;quanteda&quot;) install.packages(&quot;tm&quot;) install.packages(&quot;udpipe&quot;) library(quanteda) library(tm) library(udpipe) One common procedure is to split texts into sentences which we can do by using, e.g., the tokenize_sentence function from the quanteda package. I also unlist the data to have a vector wot work with (rather than a list). et_sent &lt;- quanteda::tokenize_sentence(review) %&gt;% unlist() # inspect et_sent ## textpos10001 ## &quot;Gary Busey is superb in this musical biography.&quot; ## textpos10002 ## &quot;Great singing and excellent soundtrack.&quot; ## textpos10003 ## &quot;The Buddy Holly Story is a much better movie than La Bamba.&quot; ## textpos10004 ## &quot;From reading other comments, there may be some historical inaccuracies.&quot; ## textpos10005 ## &quot;Regardless, it is a fun toe-tapping film, and a good introduction to Buddy Holly&#39;s music.&quot; ## textpos10006 ## &quot;&quot; Another common procedure is to remove stop words, i.e., words that do not have semantic or referential meaning (like nouns such as tree or cat, or verbs like sit or speak or adjectives such as green or loud) but that indicate syntactic relations, roles, or features.(e.g., articles and pronouns). We can remove stopwords using, e.g., the removeWords function from the tm package et_wostop &lt;- tm::removeWords(review, tm::stopwords(&quot;english&quot;)) # inspect et_wostop ## textpos1000 ## &quot;Gary Busey superb musical biography. Great singing excellent soundtrack. The Buddy Holly Story much better movie La Bamba. From reading comments, may historical inaccuracies. Regardless, fun toe-tapping film, good introduction Buddy Holly&#39;s music.\\r\\n&quot; To remove the superfluous white spaces, we can use, e.g., the stripWhitespace function from the tm package. et_wows &lt;- tm::stripWhitespace(et_wostop) # inspect et_wows ## textpos1000 ## &quot;Gary Busey superb musical biography. Great singing excellent soundtrack. The Buddy Holly Story much better movie La Bamba. From reading comments, may historical inaccuracies. Regardless, fun toe-tapping film, good introduction Buddy Holly&#39;s music. &quot; It can also be useful to remove numbers. We can do this using, e.g., the removeNumbers function from the tm package. et_wonum &lt;- tm::removeNumbers(&quot;This is the 1 and only sentence I will write in 2022.&quot;) # inspect et_wonum ## [1] &quot;This is the and only sentence I will write in .&quot; We may also want to remove any type of punctuation using, e.g., the removePunctuation function from the tm package. et_wopunct &lt;- tm::removePunctuation(review) # inspect et_wopunct ## textpos1000 ## &quot;Gary Busey is superb in this musical biography Great singing and excellent soundtrack The Buddy Holly Story is a much better movie than La Bamba From reading other comments there may be some historical inaccuracies Regardless it is a fun toetapping film and a good introduction to Buddy Hollys music\\r\\n&quot; 5.1 Stemming Stemming is the process of reducing a word to its base or root form, typically by removing suffixes. For example, running becomes run and jumps becomes jump. This helps in normalizing words to their core meaning for text analysis and natural language processing tasks. We can stem a text using, e.g., the stemDocument function from the tm package et_stem &lt;- tm::stemDocument(review, language = &quot;en&quot;) # inspect et_stem ## textpos1000 ## &quot;Gari Busey is superb in this music biography. Great sing and excel soundtrack. The Buddi Holli Stori is a much better movi than La Bamba. From read other comments, there may be some histor inaccuracies. Regardless, it is a fun toe-tap film, and a good introduct to Buddi Holli music.&quot; 5.2 Part-of-speech tagging and dependency parsing A far better option than stemming is lemmatization as lemmatization is based on proper morphological information and vocabularies. For lemmatization, we can use the udpipe package which also tokenizes texts, adds part-of-speech tags, and provides information about dependency relations. Before we can tokenize, lemmatize, pos-tag and parse though, we need to download a pre-trained language model. # download language model m_eng &lt;- udpipe::udpipe_download_model(language = &quot;english-ewt&quot;) If you have downloaded a model once, you can also load the model directly from the place where you stored it on your computer. In my case, I have stored the model in a folder called udpipemodels # load language model from your computer after you have downloaded it once m_eng &lt;- udpipe::udpipe_load_model(file = here::here(&quot;english-ewt-ud-2.5-191206.udpipe&quot;)) We can now use the model to annotate out text. # tokenise, tag, dependency parsing text_anndf &lt;- udpipe::udpipe_annotate(m_eng, x = review) %&gt;% as.data.frame() %&gt;% dplyr::select(-sentence) # inspect head(text_anndf, 10) ## doc_id paragraph_id sentence_id token_id token lemma upos xpos ## 1 doc1 1 1 1 Gary Gary PROPN NNP ## 2 doc1 1 1 2 Busey Busey PROPN NNP ## 3 doc1 1 1 3 is be AUX VBZ ## 4 doc1 1 1 4 superb superb ADJ JJ ## 5 doc1 1 1 5 in in ADP IN ## 6 doc1 1 1 6 this this DET DT ## 7 doc1 1 1 7 musical musical ADJ JJ ## feats head_token_id dep_rel ## 1 Number=Sing 4 nsubj ## 2 Number=Sing 1 flat ## 3 Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin 4 cop ## 4 Degree=Pos 0 root ## 5 &lt;NA&gt; 8 case ## 6 Number=Sing|PronType=Dem 8 det ## 7 Degree=Pos 8 amod ## deps misc ## 1 &lt;NA&gt; &lt;NA&gt; ## 2 &lt;NA&gt; &lt;NA&gt; ## 3 &lt;NA&gt; &lt;NA&gt; ## 4 &lt;NA&gt; &lt;NA&gt; ## 5 &lt;NA&gt; &lt;NA&gt; ## 6 &lt;NA&gt; &lt;NA&gt; ## 7 &lt;NA&gt; &lt;NA&gt; ## [ reached &#39;max&#39; / getOption(&quot;max.print&quot;) -- omitted 3 rows ] We could, of course, perform many more manipulations of textual data but this should suffice to get you started. 5.3 Example: Data processing chain When working with texts, we usually need to clean the data. Below, we do some basic cleaning using a pipeline or data processing chain. In a data processing chain, we combine commands to achieve an end result (in our case, a clean text). reviews_pos_split_clean &lt;- reviews_pos_split %&gt;% # replace elements stringr::str_replace_all(&quot;&lt;.*?&gt;&quot;, &quot; &quot;) %&gt;% # convert to lower case tolower() %&gt;% # remove strange symbols stringr::str_replace_all(&quot;[^[:alnum:][:punct:]]+&quot;, &quot; &quot;) %&gt;% # remove \\&quot; stringr::str_remove_all(&quot;\\&quot;&quot;) %&gt;% # remove superfluous white spaces stringr::str_squish() # remove very short elements reviews_pos_split_clean &lt;- reviews_pos_split_clean[nchar(reviews_pos_split_clean) &gt; 10] # inspect data nchar(reviews_pos_split_clean) ## [1] 1728 639 581 456 126 182 3833 151 683 29 104 91 42 25 714 ## [16] 461 405 250 95 57 719 368 1502 121 1636 709 44 681 78 222 ## [31] 904 247 516 1935 2671 1148 2548 815 705 27 108 209 30 553 287 ## [46] 896 424 64 546 61 195 32 43 39 199 120 615 81 133 290 ## [61] 45 278 20 231 77 98 340 1957 377 41 35 41 303 716 32 ## [76] 52 218 1117 1764 220 98 212 576 70 26 780 242 130 241 87 ## [91] 249 109 63 81 464 101 369 34 464 19 ## [ reached getOption(&quot;max.print&quot;) -- omitted 2656 entries ] Inspect text reviews_pos_split_clean[1] 5.4 Concordancing and KWICs Creating concordances or key-word-in-context displays is one of the most common practices when dealing with text data. Fortunately, there exist ready-made functions that make this a very easy task in R. We will use the kwic function from the quanteda package to create kwics here. kwic_multiple &lt;- quanteda::kwic(reviews_pos_split_clean, pattern = phrase(&quot;audience&quot;), window = 3, valuetype = &quot;regex&quot;) %&gt;% as.data.frame() # inspect data head(kwic_multiple) ## docname from to pre keyword post ## 1 text1 222 222 painted for mainstream audiences , forget charm ## 2 text9 90 90 community . the audience at the end ## 3 text35 36 36 often find big audiences . people seem ## 4 text37 188 188 this keeps the audience on the edge ## 5 text37 376 376 krabbé holds the audience&#39;s attention and looks ## 6 text76 8 8 message to the audience . his ## pattern ## 1 audience ## 2 audience ## 3 audience ## 4 audience ## 5 audience ## 6 audience We can now also select concordances based on specific features. For example, we only want those instances of “great again” if the preceding word was “America”. kwic_multiple_select &lt;- kwic_multiple %&gt;% # last element before search term is &quot;the&quot; dplyr::filter(str_detect(pre, &quot;the$&quot;)) # inspect data head(kwic_multiple_select) ## docname from to pre keyword post pattern ## 1 text9 90 90 community . the audience at the end audience ## 2 text37 188 188 this keeps the audience on the edge audience ## 3 text37 376 376 krabbé holds the audience&#39;s attention and looks audience ## 4 text76 8 8 message to the audience . his audience ## 5 text77 32 32 message for the audience . they are audience ## 6 text169 123 123 home gives the audience enough sympathy to audience Again, we can use the write.table function to save our kwics to disc. write.table(kwic_multiple_select, here::here(&quot;data&quot;, &quot;kwic_multiple_select.txt&quot;), sep = &quot;\\t&quot;) As most of the data that we use is on out computers (rather than being somewhere on the web), we now load files with text from your computer. We now turn to data visualization basics. "],["basics-of-data-visualization.html", "Section 6 Basics of Data Visualization 6.1 Basics of ggplot2 syntax 6.2 Line plot 6.3 Prettifying plots 6.4 Combining plots 6.5 Boxplots 6.6 Barplots 6.7 Going further 6.8 Ending R sessions", " Section 6 Basics of Data Visualization There are numerous function in R that we can use to visualize data. We will use the ggplot function from the ggplot2 package here to visualize the data. The ggplot2 package was developed by Hadley Wickham in 2005 and it implements the graphics scheme described in the book The Grammar of Graphics by Leland Wilkinson. The idea behind the Grammar of Graphics can be boiled down to 5 bullet points (see Wickham 2016: 4): a statistical graphic is a mapping from data to aesthetic attributes (location, color, shape, size) of geometric objects (points, lines, bars). the geometric objects are drawn in a specific coordinate system. scales control the mapping from data to aesthetics and provide tools to read the plot (i.e., axes and legends). the plot may also contain statistical transformations of the data (means, medians, bins of data, trend lines). faceting can be used to generate the same plot for different subsets of the data. 6.1 Basics of ggplot2 syntax Specify data, aesthetics and geometric shapes ggplot(data, aes(x=, y=, color=, shape=, size=)) + geom_point(), or geom_histogram(), or geom_boxplot(), etc. This combination is very effective for exploratory graphs. The data must be a data frame. The aes() function maps columns of the data frame to aesthetic properties of geometric shapes to be plotted. ggplot() defines the plot; the geoms show the data; each component is added with + Some examples should make this clear Before we start plotting, we will load tabular data (information about the speakers in the dinner conversations) and the prepare the data that we want to visualize. From this table, we create two versions: a basic cleaned version a summary table with the mean word counts by gender and age. # create clean basic table readxl::read_excel(here::here(&quot;data&quot;, &quot;ICEdata.xlsx&quot;)) %&gt;% # only private dialogue dplyr::filter(stringr::str_detect(text.id, &quot;S1A&quot;), # without speaker younger than 19 age != &quot;0-18&quot;, age != &quot;NA&quot;, sex != &quot;NA&quot;, word.count &gt; 10) %&gt;% dplyr::mutate(age = factor(age), sex = factor(sex), date = factor(date)) -&gt; pdat # create summary table readxl::read_excel(here::here(&quot;data&quot;, &quot;ICEdata.xlsx&quot;)) %&gt;% # only private dialogue dplyr::filter(stringr::str_detect(text.id, &quot;S1A&quot;), # without speaker younger than 19 age != &quot;0-18&quot;, age != &quot;NA&quot;) %&gt;% dplyr::group_by(sex, age) %&gt;% dplyr::summarise(words = mean(word.count)) -&gt; psum # inspect head(pdat); head(psum) ## # A tibble: 6 × 9 ## id file.speaker.id text.id spk.ref zone date sex age word.count ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; ## 1 1 &lt;S1A-001$A&gt; S1A-001 A northern i… 1990… male 34-41 765 ## 2 2 &lt;S1A-001$B&gt; S1A-001 B northern i… 1990… fema… 34-41 1298 ## 3 4 &lt;S1A-002$A&gt; S1A-002 A northern i… 2002… fema… 26-33 391 ## 4 5 &lt;S1A-002$B&gt; S1A-002 B northern i… 2002… fema… 19-25 47 ## 5 6 &lt;S1A-002$C&gt; S1A-002 C northern i… 2002… male 50+ 200 ## 6 7 &lt;S1A-002$D&gt; S1A-002 D northern i… 2002… fema… 50+ 464 ## # A tibble: 6 × 3 ## # Groups: sex [2] ## sex age words ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 female 19-25 562. ## 2 female 26-33 531. ## 3 female 34-41 543. ## 4 female 42-49 501. ## 5 female 50+ 632. ## 6 male 19-25 570. We will now create some basic visualizations or plots. 6.2 Line plot In the example below, we specify that we want to visualize the plotdata and that the x-axis should represent Age and the y-axis Words(the mean frequency of words). We also tell R that we want to group the data by Sex (i.e. that we want to distinguish between men and women). Then, we add geom_line which tells R that we want a line graph. The result of this is shown below. ggplot(psum, aes(x = age, y = words, group = sex, color = sex)) + geom_line() 6.3 Prettifying plots Once you have a basic plot like the one above, you can prettify the plot. For example, you can change the width of the lines (size = 1.25) change the y-axis limits (coord_cartesian(ylim = c(0, 1000))) use a different theme (theme_bw() means black and white theme) move the legend to the top change the default colors to colors you like (*scale_color_manual …`) change the linetype (scale_linetype_manual ...) psum %&gt;% ggplot(aes(x = age, y = words, color = sex, group = sex, linetype = sex)) + geom_line(size = 1.25) + coord_cartesian(ylim = c(0, 1500)) + theme_bw() + theme(legend.position = &quot;top&quot;) + scale_color_manual(breaks = c(&quot;female&quot;, &quot;male&quot;), values = c(&quot;gray20&quot;, &quot;gray50&quot;)) + scale_linetype_manual(breaks = c(&quot;female&quot;, &quot;male&quot;), values = c(&quot;solid&quot;, &quot;dotted&quot;)) + labs(x = &quot;Age groups&quot;, y = &quot;Average word count\\n(per 1,000 words)&quot;) 6.4 Combining plots An additional and very handy feature of this way of producing graphs is that you can integrate them into pipes can easily combine plots. Below, we first generate a scatter plot with geom_jitter and then add a line plot by summarising the data. pdat %&gt;% ggplot(aes(x = age, y = word.count, color = sex, linetype = sex)) + geom_jitter(alpha = .5, width = .2) + stat_summary(fun=mean, geom=&quot;line&quot;, aes(group=sex)) + coord_cartesian(ylim = c(0, 2500)) + theme_bw() + theme(legend.position = &quot;top&quot;) + scale_color_manual(breaks = c(&quot;female&quot;, &quot;male&quot;), values = c(&quot;indianred&quot;, &quot;darkblue&quot;)) + scale_linetype_manual(breaks = c(&quot;female&quot;, &quot;male&quot;), values = c(&quot;solid&quot;, &quot;dotted&quot;)) 6.5 Boxplots Below, we generate a boxplot using geom_box and break it up into different facets. pdat %&gt;% ggplot(aes(x = age, y = word.count, fill = sex)) + facet_grid(vars(date)) + geom_boxplot() + coord_cartesian(ylim = c(0, 2000)) + theme_bw() + theme(legend.position = &quot;top&quot;) + scale_fill_manual(breaks = c(&quot;female&quot;, &quot;male&quot;), values = c(&quot;#E69F00&quot;, &quot;#56B4E9&quot;)) 6.6 Barplots To exemplify a bar plot, we generate a plot with geom_bar which shows the number of men and women by Date. pdat %&gt;% dplyr::select(date, sex, text.id) %&gt;% unique() %&gt;% dplyr::group_by(date, sex) %&gt;% dplyr::summarize(speakers = n()) %&gt;% ggplot(aes(x = date, y = speakers, fill = date, label = speakers)) + facet_wrap(vars(sex), ncol = 2) + geom_bar(stat = &quot;identity&quot;) + geom_text(vjust=-1.6, color = &quot;black&quot;) + coord_cartesian(ylim = c(0, 100)) + theme_bw() + scale_fill_manual(breaks = c(&quot;1990-1994&quot;, &quot;1995-2001&quot;, &quot;2002-2005&quot;), values = c(&quot;#E69F00&quot;, &quot;lightgray&quot;, &quot;#56B4E9&quot;)) 6.7 Going further If you want to know more, there are various online resources available to learn R (you can check out a very recommendable introduction here). Here are also some additional resources that you may find helpful: Grolemund. G., and Wickham, H., R 4 Data Science, 2017. Highly recommended! (especially chapters 1, 2, 4, 6, and 8) Stat545 - Data wrangling, exploration, and analysis with R. University of British Columbia. http://stat545.com/ Swirlstats, a package that teaches you R and statistics within R: https://swirlstats.com/ DataCamp’s (free) Intro to R interactive tutorial: https://www.datacamp.com/courses/free-introduction-to-r DataCamp’s advanced R tutorials require a subscription. *Twitter: Explore RStudio Tips https://twitter.com/rstudiotips Explore #rstats, #rstudioconf 6.8 Ending R sessions At the end of each session, you can extract information about the session itself (e.g. which R version you used and which versions of packages). This can help others (or even your future self) to reproduce the analysis that you have done. You can extract the session information by running the sessionInfo function (without any arguments) sessionInfo() ## R version 4.3.2 (2023-10-31 ucrt) ## Platform: x86_64-w64-mingw32/x64 (64-bit) ## Running under: Windows 11 x64 (build 22621) ## ## Matrix products: default ## ## ## locale: ## [1] LC_COLLATE=English_Australia.utf8 LC_CTYPE=English_Australia.utf8 ## [3] LC_MONETARY=English_Australia.utf8 LC_NUMERIC=C ## [5] LC_TIME=English_Australia.utf8 ## ## time zone: Australia/Brisbane ## tzcode source: internal ## ## attached base packages: ## [1] stats graphics grDevices datasets utils methods base ## ## other attached packages: ## [1] udpipe_0.8.11 flextable_0.9.5 here_1.0.1 tokenizers_0.3.0 ## [5] tm_0.7-12 NLP_0.2-1 readxl_1.4.3 quanteda_3.3.1 ## [9] tidytext_0.4.1 lubridate_1.9.3 forcats_1.0.0 stringr_1.5.1 ## [13] dplyr_1.1.4 purrr_1.0.2 readr_2.1.5 tidyr_1.3.1 ## [17] tibble_3.2.1 ggplot2_3.5.0 tidyverse_2.0.0 ## ## loaded via a namespace (and not attached): ## [1] tidyselect_1.2.1 farver_2.1.1 fastmap_1.1.1 ## [4] fontquiver_0.2.1 janeaustenr_1.0.0 promises_1.2.1 ## [7] digest_0.6.35 timechange_0.3.0 mime_0.12 ## [10] lifecycle_1.0.4 gfonts_0.2.0 magrittr_2.0.3 ## [13] compiler_4.3.2 rlang_1.1.3 sass_0.4.9 ## [16] tools_4.3.2 utf8_1.2.4 yaml_2.3.8 ## [19] data.table_1.15.2 knitr_1.45 labeling_0.4.3 ## [22] askpass_1.2.0 stopwords_2.3 curl_5.2.1 ## [25] xml2_1.3.6 klippy_0.0.0.9500 httpcode_0.3.0 ## [28] withr_3.0.0 grid_4.3.2 fansi_1.0.6 ## [31] gdtools_0.3.7 xtable_1.8-4 colorspace_2.1-0 ## [34] scales_1.3.0 crul_1.4.0 cli_3.6.2 ## [37] rmarkdown_2.26 crayon_1.5.2 ragg_1.3.0 ## [40] generics_0.1.3 RcppParallel_5.1.7 rstudioapi_0.16.0 ## [43] tzdb_0.4.0 cachem_1.0.8 assertthat_0.2.1 ## [46] parallel_4.3.2 cellranger_1.1.0 vctrs_0.6.5 ## [49] Matrix_1.6-5 jsonlite_1.8.8 slam_0.1-50 ## [52] fontBitstreamVera_0.1.1 bookdown_0.38 hms_1.1.3 ## [55] systemfonts_1.0.6 jquerylib_0.1.4 glue_1.7.0 ## [58] stringi_1.8.3 gtable_0.3.4 later_1.3.2 ## [61] munsell_0.5.0 pillar_1.9.0 htmltools_0.5.8 ## [64] openssl_2.1.1 R6_2.5.1 textshaping_0.3.7 ## [67] rprojroot_2.0.4 evaluate_0.23 shiny_1.8.1 ## [70] lattice_0.21-9 highr_0.10 SnowballC_0.7.1 ## [73] renv_1.0.5 fontLiberation_0.1.0 httpuv_1.6.15 ## [76] bslib_0.7.0 zip_2.3.1 uuid_1.2-0 ## [79] Rcpp_1.0.12 fastmatch_1.1-4 officer_0.6.5 ## [82] xfun_0.43 pkgconfig_2.0.3 "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
